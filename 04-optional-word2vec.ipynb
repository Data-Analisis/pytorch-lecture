{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "\"Word2vec is a technique for natural language processing. The word2vec algorithm uses a neural network model to learn word associations from a large corpus of text. Once trained, such a model can detect synonymous words or suggest additional words for a partial sentence. As the name implies, word2vec represents each distinct word with a particular list of numbers called a vector. The vectors are chosen carefully such that a simple mathematical function (the cosine similarity between the vectors) indicates the level of semantic similarity between the words represented by those vectors.\" [https://en.wikipedia.org/wiki/Word2vec]\n",
    "\n",
    "Here we will build a PyTorch model that implements Word2Vec's CBOW strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', 'are', 'about', 'to', 'study', 'the', 'idea', 'of', 'a', 'computational', 'process.']\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "print(raw_text[:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "{'by': 2, 'we': 3, 'computers.': 4, 'they': 5, 'called': 6, 'computer': 7, 'The': 8, 'is': 9, 'rules': 10, 'a': 11, 'effect,': 12, 'to': 13, 'are': 14, 'things': 15, 'data.': 16, 'our': 17, 'computational': 18, 'direct': 19, 'process.': 20, 'of': 21, 'beings': 22, 'spells.': 23, 'We': 24, 'evolve,': 25, 'directed': 26, 'programs': 27, 'pattern': 28, 'In': 29, 'conjure': 30, 'program.': 31, 'manipulate': 32, 'evolution': 33, 'idea': 34, 'about': 35, 'with': 36, 'abstract': 37, 'inhabit': 38, 'As': 39, 'spirits': 40, 'Computational': 41, 'study': 42, 'process': 43, 'processes': 44, 'People': 45, 'processes.': 46, 'that': 47, 'the': 48, 'create': 49, 'other': 50}\n"
     ]
    }
   ],
   "source": [
    "# By deriving a set from `raw_text`, we deduplicate the array\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# shifted by 2 due to special tokens for padding and unknown tokens\n",
    "word_to_ix = {word: i + 2 for i, word in enumerate(vocab)}\n",
    "ix_to_word = list(word_to_ix.values())\n",
    "print(vocab_size)\n",
    "print(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['study', 'to', 'are', 'We'], 'about'), (['the', 'study', 'about', 'are'], 'to'), (['idea', 'the', 'to', 'about'], 'study'), (['of', 'idea', 'study', 'to'], 'the'), (['a', 'of', 'the', 'study'], 'idea')]\n"
     ]
    }
   ],
   "source": [
    "context_size = 2  # 2 words to the left, 2 to the right\n",
    "data = []\n",
    "for i in range(context_size, len(raw_text) - context_size):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1], raw_text[i + 1], raw_text[i + 2]]\n",
    "    context = [raw_text[i - j] for j in range(- context_size, context_size + 1) if j != 0]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['study', 'to', 'about', 'are', 'We'], 'about'), (['the', 'study', 'to', 'about', 'are'], 'to'), (['idea', 'the', 'study', 'to', 'about'], 'study'), (['of', 'idea', 'the', 'study', 'to'], 'the'), (['a', 'of', 'idea', 'the', 'study'], 'idea')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([40, 11, 33, 12, 22])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        self.embeddings = nn.Embedding(vocab_size, emb_size)\n",
    "        self.lin_out = nn.Linear(emb_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (bs, 4, vocab_size) -> (bs, 4, emb_dim)\n",
    "        x = self.emb(x)\n",
    "        # (bs, 4, emb_dim) -> (bs, 4*emb_dim)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # (bs, 4*emb_dim) -> (bs, vocab_size)\n",
    "        x = self.lin_out(x)\n",
    "        return torch.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Instantiate the model and write a proper training loop. Here are some functions to help you make the data ready for use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_ids(context, word_to_ix):\n",
    "    list_of_ids = []\n",
    "    for w in context:\n",
    "        if w in word_to_ix:\n",
    "            list_of_ids.append(word_to_ix[w])\n",
    "        else:\n",
    "            list_of_ids.append(1)  # unknown id = 1\n",
    "    return list_of_ids\n",
    "\n",
    "\n",
    "def get_target_id(target, word_to_ix):\n",
    "    target_word_id = 0\n",
    "    if target in word_to_ix:\n",
    "        target_word_id = word_to_ix[target]\n",
    "    return target_word_id\n",
    "\n",
    "\n",
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = get_list_of_ids(context, word_to_ix)\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 13, 14, 24]\n",
      "35\n",
      "tensor([42, 13, 14, 24])\n"
     ]
    }
   ],
   "source": [
    "print(get_list_of_ids(data[0][0], word_to_ix))\n",
    "print(get_target_id(data[0][1], word_to_ix))\n",
    "print(make_context_vector(data[0][0], word_to_ix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More information\n",
    "\n",
    "If you like, these PyTorch's NLP tutorials are a good place to start building NLP models:\n",
    "\n",
    "- https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "- https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "- https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "- https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html\n",
    "- https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
