{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "\"Word2vec is a technique for natural language processing. The word2vec algorithm uses a neural network model to learn word associations from a large corpus of text. Once trained, such a model can detect synonymous words or suggest additional words for a partial sentence. As the name implies, word2vec represents each distinct word with a particular list of numbers called a vector. The vectors are chosen carefully such that a simple mathematical function (the cosine similarity between the vectors) indicates the level of semantic similarity between the words represented by those vectors.\" [https://en.wikipedia.org/wiki/Word2vec]\n",
    "\n",
    "Here we will build a PyTorch model that implements Word2Vec's CBOW strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/profile/Daniel_Braun6/publication/326588219/figure/fig1/AS:652185784295425@1532504616288/Continuous-Bag-of-words-CBOW-CB-and-Skip-gram-SG-training-model-illustrations.png\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "print(raw_text[:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# By deriving a set from `raw_text`, we deduplicate the array\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# shifted by 2 due to special tokens for padding and unknown tokens\n",
    "word_to_ix = {word: i + 2 for i, word in enumerate(vocab)}\n",
    "ix_to_word = list(word_to_ix.values())\n",
    "print(vocab_size)\n",
    "print(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 2  # 2 words to the left, 2 to the right\n",
    "data = []\n",
    "for i in range(context_size, len(raw_text) - context_size):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1], raw_text[i + 1], raw_text[i + 2]]\n",
    "    context = [raw_text[i - j] for j in range(- context_size, context_size + 1) if j != 0]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        self.embeddings = nn.Embedding(vocab_size, emb_size)\n",
    "        self.lin_out = nn.Linear(emb_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (bs, 4, vocab_size) -> (bs, 4, emb_dim)\n",
    "        x = self.emb(x)\n",
    "        # (bs, 4, emb_dim) -> (bs, emb_dim)\n",
    "        x = x.sum(dim=1)\n",
    "        # (bs, emb_dim) -> (bs, vocab_size)\n",
    "        logits = self.lin_out(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Instantiate the model and write a proper training loop. Here are some functions to help you make the data ready for use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_ids(context, word_to_ix):\n",
    "    list_of_ids = []\n",
    "    for w in context:\n",
    "        if w in word_to_ix:\n",
    "            list_of_ids.append(word_to_ix[w])\n",
    "        else:\n",
    "            list_of_ids.append(1)  # unknown id = 1\n",
    "    return list_of_ids\n",
    "\n",
    "\n",
    "def get_target_id(target, word_to_ix):\n",
    "    target_word_id = 0\n",
    "    if target in word_to_ix:\n",
    "        target_word_id = word_to_ix[target]\n",
    "    return target_word_id\n",
    "\n",
    "\n",
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = get_list_of_ids(context, word_to_ix)\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_list_of_ids(data[0][0], word_to_ix))\n",
    "print(get_target_id(data[0][1], word_to_ix))\n",
    "print(make_context_vector(data[0][0], word_to_ix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More information\n",
    "\n",
    "If you like, these PyTorch's NLP tutorials are a good place to start building NLP models:\n",
    "\n",
    "- https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "- https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "- https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "- https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html\n",
    "- https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
